<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Handtrack</title>
    <script src="https://cdn.jsdelivr.net/npm/handtrackjs/dist/handtrack.min.js"></script>
</head>
<body>
<!-- Replace this with your image. Make sure CORS settings allow reading the image! -->
<button onclick="toggleVideo()" id="trackbutton" class="bx--btn bx--btn--secondary" type="button">
    Toggle Video
</button>
<div id="updatenote" class="updatenote mt10"> loading model ..</div>
<video class="videobox canvasbox" autoplay="autoplay" id="myvideo"></video>

<canvas id="canvas" class="border canvasbox"></canvas>

<!-- Place your code in the script tag below. You can also use an external .js file -->
<script src="https://cdn.jsdelivr.net/npm/handtrackjs/dist/handtrack.min.js"> </script>
<script>

    // Notice there is no 'import' statement. 'handTrack' and 'tf' is
    // available on the index-page because of the script tag above.
    const video = document.getElementById("myvideo");
    const canvas = document.getElementById("canvas");
    const context = canvas.getContext("2d");

    let trackButton = document.getElementById("trackbutton");
    let updateNote = document.getElementById("updatenote");

    let isVideo = false;
    let model = null;

    toggleVideo()

    const modelParams = {
        flipHorizontal: true,   // flip e.g for video
        maxNumBoxes: 20,        // maximum number of boxes to detect
        iouThreshold: 0.5,      // ioU threshold for non-max suppression
        scoreThreshold: 0.6,    // confidence threshold for predictions.
    }

    function startVideo() {
        handTrack.startVideo(video).then(function (status) {
            console.log("video started", status);
            if (status) {
                console.log("Video started. Now tracking")
                isVideo = true
                runDetection()
            } else {
                console.log("Please enable video")
            }
        });
    }

    function toggleVideo() {
        console.log(isVideo)
        if (!isVideo) {
            console.log("Starting video")
            startVideo();
        } else {
            console.log("Stopping video")
            handTrack.stopVideo(video)
            isVideo = false;
            console.log("Video stopped")
        }
    }


    function runDetection() {
        model.detect(video).then(predictions => {
            console.log("Predictions: ", predictions);
            model.renderPredictions(predictions, canvas, context, video);
            if (isVideo) {
                requestAnimationFrame(runDetection);
            }
        });
    }

    // Load the model.
    handTrack.load(modelParams).then(lmodel => {
        // detect objects in the image.
        model = lmodel
        updateNote.innerText = "Loaded Model!"
        trackButton.disabled = false
    });

</script>
</body>
</html>
